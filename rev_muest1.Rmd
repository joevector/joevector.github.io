---
title: "Revision de Muestreo - Parte 1"
author: "Boris Fazio"
date: "14 de junio de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Nociones generales de muestreo

### Definicion de muestreo

Para hablar de muestreo requerimos identificar, como minimo, un contexto en el que:

* Podemos identificar un conjunto bien definido de entidades, una **poblacion**

* Nos interesa conocer el comportamiento poblacional de alguna caracteristica de dichas entidades, un **parametro**

Entonces, **muestreo** describe un proceso por el cual se procede con la seleccion de un subconjunto de entidades de la poblacion de forma tal que la probabilidad de obtener cualquier coleccion especifica de observaciones sea conocida.

Si existe informacion adicional a la arriba mencionada, estaremos en condicion de usar tecnicas de muestreo mas sofisticadas. Entonces, la clave para hacer un buen muestreo es reconocer los datos que conocemos al inicio del problema, las tecnicas aplicables en ese contexto y las propiedades de cada una a fin de tomar una decision optima.

### Inferencia estadistica

Dado que el proceso de generacion de muestras tiene propiedades probabilisticas conocidas, podemos anticipar la relacion entre las medidas que tomemos de una muestra y el valor de algun parametro en la poblacion de origen. Se llama **estadistico** a cualquier funcion de las variables en una muestra, pero si usamos un estadistico como aproximacion al valor de un parametro, entonces tambien se le llama **estimador**.

Para cuantificar la calidad de informacion que esperamos obtener con algun estimador dado, calculamos sus propiedades estadisticas. Las propiedades que se evaluan con mayor frecuencia son **sesgo** y **varianza**.

Una vez realizado un muestreo y elegido un estimador, el valor concreto que se calcula se denomina **estimacion puntual**. Dado que la varianza del estimador es una cantidad que tambien se puede estimar, podemos tomar esta informacion para generar una **estimacion por intervalo**, lo que provee una nocion de nuestra certeza acerca del valor real del parametro.

## Muestreo Aleatorio Simple (MAS)

Este es el metodo de muestreo mas basico y asigna la misma probabilidad de seleccion a todas las muestras posibles.

**Informacion requerida:**

* Listado completo de los elementos de la poblacion
    * $\mathcal{P} = \{e_1, ..., e_N\}$

**Estimadores comunes:**

* Media poblacional
    * $\hat\mu = \bar Y = \frac{1}{n}\sum_{i=1}^n Y_i$
    
* Varianza poblacional
    * $\hat\sigma^2 = S^2 = \frac{1}{n-1}\sum_{i=1}^n (\bar Y - Y_i)^2$

Las propiedades estadisticas de estos estimadores dependen del procedimiento preciso que se use para generar la muestra. A continuacion, las dos posibilidades que existen.

### MAS con reemplazo (MASc)

**Pasos a seguir:**

1. Asignar probabilidad de seleccion $1/N$ a todo $e \in \mathcal{P}$.

2. Elegir un $e$ al azar y agregarlo a la muestra

3. Repetir 2 hasta que la muestra tenga el tamano $n$ deseado

**Propiedades de los estimadores:**

* Media
    * $\text{E}(\bar Y) = \mu$
    
    * $\text{V}(\bar Y) =  \sigma^2 / n$
    
* Varianza
    * $\text{E}(S^2) = \sigma^2$

**Implementacion en R**
```{r, include=FALSE}
library(survey)
```
```{r}
## Seleccion de la muestra

set.seed(321)

# Informacion requerida:
    # Poblacion
P <- data.frame(id=1:15,y=rpois(15,10))
    # Tamano de muestra
n <- 8

# Seleccion de muestra:
muestra <- P[sample(nrow(P), size=n, replace=TRUE),]
y <- muestra$y

## Calculo de los estimadores
yb<-0;ve<-0;ybvar<-0

# Con funciones de R base:
    # Media
yb[1] <- sum(y)/n
yb[2] <- mean(y)
    # Varianza de y
ve[1] <- sum((yb[1]-y)**2)/(n-1)
ve[2] <- var(y)
    # Varianza de la media de y
ybvar[1] <- ve[1]/n

# Con paquete survey:
library(survey)

  # Definir esquema de muestreo
muestra_svy <- svydesign(~1, data=muestra)
    # Media (incluye calculo de su varianza)
yb_svy <- svymean(y,muestra_svy)
    # Varianza de y
ve_svy <- svyvar(y,muestra_svy)

yb[3]<-yb_svy;ve[3]<-ve_svy
ybvar[2]<-attr(yb_svy, which = "var")

# Verificamos equivalencia de los metodos
yb;ve;ybvar
```

### MAS sin reemplazo (MASs)

**Pasos a seguir:**

1. Asignar probabilidad de seleccion $1/N$ a todo $e \in \mathcal{P}$.

2. Elegir un $e$ al azar y agregarlo a la muestra

3. Repetir 2 hasta que la muestra tenga el tamano $n$ deseado

**Propiedades de los estimadores:**

* Media
    * $\text{E}(\bar Y) = \mu$
    
    * $\text{V}(\bar Y) =  \left(1-\frac{n}{N}\right)\sigma_{N-1}^2/n$
    
* Varianza
    * $\text{E}(S^2) = \sigma_{N-1}^2$

**Implementacion en R**
```{r, include=FALSE}
library(survey)
```
```{r}
## Seleccion de la muestra

set.seed(321)

# Informacion requerida:
    # Poblacion y su tamano
P <- data.frame(id=1:15,y=rpois(15,10))
N <- nrow(P)
    # Tamano de muestra
n <- 8

# Seleccion de muestra:
muestra <- cbind(P[sample(nrow(P), size=n),],
                 fpc=n/N)
y <- muestra$y

## Calculo de los estimadores

# Con funciones de R base:
    # Media
yb <- mean(y)
    # Varianza de y
ve <- var(y)
    # Varianza de la media de y
ybvar <- (1-n/N)*ve/n

# Con paquete survey:
library(survey)

  # Definir esquema de muestreo
muestra_svy <- svydesign(~1, data=muestra, fpc=~fpc)
    # Media (incluye calculo de su varianza)
yb_svy <- svymean(y,muestra_svy)
    # Varianza de y
ve_svy <- svyvar(y,muestra_svy)

# Verificamos equivalencia de los metodos
c(yb,yb_svy);c(ve,ve_svy);c(ybvar,attr(yb_svy, which = "var"))
```

### Ejemplos desarrollados

#### Teoria: Ejercicio 2.2

Juan, Pepe, Rosa, Luis, y Maria participan en un sorteo donde se repartiran al azar entre ellos 4 vales de 50 soles cada uno.

a) Si Juan desea ganar algun vale 多que es lo que mas le convendria: que la seleccion se haga con o sin reemplazamiento?

---

**Interpretacion del enunciado:**

* *se repartiran al azar entre ellos 4 vales*
    * Describe un proceso equivalente a realizar un MAS con $n=4$ en una poblacion de $N=5$

* *Si Juan desea ganar algun vale*
    * $P(\text{Juan} \in \mathcal{M}) = P(\text{J})$

* *多que es lo que mas le convendria?*
    * Calcular y comparar: $P_{\text{MASc}}(\text{J})$, $P_{\text{MASs}}(\text{J})$

**Resolucion:**

Por definicion, a cada elemento de la muestra, $\mathcal{M}=\{e'_1,...,e'_N\}$, corresponde un $e_j \in \mathcal{P}$ tal que $e'_i = e_j$ para algun $i$.

La probabilidad de que algun elemento particular salga elegido esta dada por

$$P(e_j \in \mathcal{M}) = P(e_j = e'_1 \cup ... \cup e_j = e'_n)$$
En el caso **MASc**, la probabilidad de seleccion de un elemento no varia entre pasos sucesivos de inclusion a la muestra, es decir que son independientes. Entonces tenemos

$$P_{\text{MASc}}(e_j \in \mathcal{M}) =1 - P(e_j \notin \mathcal{M}) = 1 - P(e_j \neq e'_1 \cap ... \cap e_j \neq e'_n) = 1 - P(e_j \neq e'_1)\times ... \times P(e_j \neq e'_n) = 1 - \left(\frac{N-1}{N}\right)^n$$

Para el caso **MASs**, ser seleccionado en algun paso es un evento excluyente para futuros pasos, entonces

$$P_{\text{MASs}}(e_j \in \mathcal{M}) =P(e_j = e'_1 \cup ... \cup e_j = e'_n) = P(e_j = e'_1) + ... + P(e_j = e'_n) = \sum_{i=0}^{n-1} \frac{1}{N-i}$$


---

b) Si la seleccion se hace con reemplazamiento 多que probabilidad hay de que Juan gane un vale y Rosa 2? 多Es esta probabilidad la misma a que Juan gane los cuatro vales?

## Muestreo Aleatorio Estratificado (MAE)

Si dividimos la poblacion segun algun criterio tal que la variable de interes tenga valores similares al interior de cada subgrupo pero notoriamente diferentes entre grupos, hemos formado **estratos**.

El MAE es un metodo que permite incorporar la informacion adicional que ofrece la variable estratificadora para obtener estimados de forma mas eficiente (en terminos de precision o de costo) que un MAS.

**Informacion requerida:**

* Listado completo de los elementos de la poblacion
    * $\mathcal{P} = \{e_1, ..., e_N\}$
   
* Membresias a estratos para cada elemento
    * $e_i \in h_j,\space \forall i = 1,...,N, \space j = 1,...,H$
    * $h_i \cap h_j = \emptyset,\space i\neq j$
