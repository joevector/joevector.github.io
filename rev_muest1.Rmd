---
title: "Revision de Muestreo - Parte 1"
author: "Boris Fazio"
date: "14 de junio de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Nociones generales de muestreo

### Definicion de muestreo

Para hablar de muestreo requerimos identificar, como minimo, un contexto en el que:

* Podemos identificar un conjunto bien definido de entidades, una **poblacion**

* Nos interesa conocer el comportamiento poblacional de alguna caracteristica de dichas entidades, un **parametro**

Entonces, **muestreo** describe un proceso por el cual se procede con la seleccion de un subconjunto de entidades de la poblacion de forma tal que la probabilidad de obtener cualquier coleccion especifica de observaciones sea conocida.

Si existe informacion adicional a la arriba mencionada, estaremos en condicion de usar tecnicas de muestreo mas sofisticadas. Entonces, la clave para hacer un buen muestreo es reconocer los datos que conocemos al inicio del problema, las tecnicas aplicables en ese contexto y las propiedades de cada una a fin de tomar una decision optima.

### Inferencia estadistica

Dado que el proceso de generacion de muestras tiene propiedades probabilisticas conocidas, podemos anticipar la relacion entre las medidas que tomemos de una muestra y el valor de algun parametro en la poblacion de origen. Se llama **estadistico** a cualquier funcion de las variables en una muestra, pero si usamos un estadistico como aproximacion al valor de un parametro, entonces tambien se le llama **estimador**.

Para cuantificar la calidad de informacion que esperamos obtener con algun estimador dado, calculamos sus propiedades estadisticas. Las propiedades que se evaluan con mayor frecuencia son **sesgo** y **varianza**.

Una vez realizado un muestreo y elegido un estimador, el valor concreto que se calcula se denomina **estimacion puntual**. Dado que la varianza del estimador es una cantidad que tambien se puede estimar, podemos tomar esta informacion para generar una **estimacion por intervalo**, lo que provee una nocion de nuestra certeza acerca del valor real del parametro.

## Muestreo Aleatorio Simple (MAS)

Este es el metodo de muestreo mas basico y asigna la misma probabilidad de seleccion a todas las muestras posibles.

**Informacion requerida:**

* Listado completo de los elementos de la poblacion
    * $\mathcal{P} = \{e_1, ..., e_N\}$

**Estimadores comunes:**

* Media poblacional
    * $\hat\mu = \bar Y = \frac{1}{n}\sum_{i=1}^n Y_i$
    
* Varianza poblacional
    * $\hat\sigma^2 = S^2 = \frac{1}{n-1}\sum_{i=1}^n (\bar Y - Y_i)^2$

Las propiedades estadisticas de estos estimadores dependen del procedimiento preciso que se use para generar la muestra. A continuacion, las dos posibilidades que existen.

### MAS con reemplazo (MASc)

**Pasos a seguir:**

1. Asignar probabilidad de seleccion $1/N$ a todo $e \in \mathcal{P}$.

2. Elegir un $e$ al azar y agregarlo a la muestra

3. Repetir 2 hasta que la muestra tenga el tamano $n$ deseado

**Propiedades de los estimadores:**

* Media
    * $\text{E}(\bar Y) = \mu$
    
    * $\text{V}(\bar Y) =  \sigma^2 / n$
    
* Varianza
    * $\text{E}(S^2) = \sigma^2$

**Implementacion en R**
```{r, include=FALSE}
library(survey)
```
```{r}
## Seleccion de la muestra

set.seed(321)

# Informacion requerida:
    # Poblacion
P <- data.frame(id=1:15,y=rpois(15,10))
    # Tamano de muestra
n <- 8

# Seleccion de muestra:
muestra <- P[sample(nrow(P), size=n, replace=TRUE),]
y <- muestra$y

## Calculo de los estimadores
yb<-0;ve<-0;ybvar<-0

# Con funciones de R base:
    # Media
yb[1] <- sum(y)/n
yb[2] <- mean(y)
    # Varianza de y
ve[1] <- sum((yb[1]-y)**2)/(n-1)
ve[2] <- var(y)
    # Varianza de la media de y
ybvar[1] <- ve[1]/n

# Con paquete survey:
library(survey)

  # Definir esquema de muestreo
muestra_svy <- svydesign(~1, data=muestra)
    # Media (incluye calculo de su varianza)
yb_svy <- svymean(y,muestra_svy)
    # Varianza de y
ve_svy <- svyvar(y,muestra_svy)

yb[3]<-yb_svy;ve[3]<-ve_svy
ybvar[2]<-attr(yb_svy, which = "var")

# Verificamos equivalencia de los metodos
yb;ve;ybvar
```

### MAS sin reemplazo (MASs)

**Pasos a seguir:**

1. Asignar probabilidad de seleccion $1/N$ a todo $e \in \mathcal{P}$.

2. Elegir un $e$ al azar y agregarlo a la muestra

3. Repetir 2 hasta que la muestra tenga el tamano $n$ deseado

**Propiedades de los estimadores:**

* Media
    * $\text{E}(\bar Y) = \mu$
    
    * $\text{V}(\bar Y) =  \sigma^2 / n$
    
* Varianza
    * $\text{E}(S^2) = \sigma^2$

**Implementacion en R**
```{r, include=FALSE}
library(survey)
```
```{r}
## Seleccion de la muestra

set.seed(321)

# Informacion requerida:
    # Poblacion
P <- data.frame(id=1:15,y=rpois(15,10))
    # Tamano de muestra
n <- 8

# Seleccion de muestra:
muestra <- P[sample(nrow(P), size=n, replace=TRUE),]
y <- muestra$y

## Calculo de los estimadores
yb<-0;ve<-0;ybvar<-0

# Con funciones de R base:
    # Media
yb[1] <- sum(y)/n
yb[2] <- mean(y)
    # Varianza de y
ve[1] <- sum((yb[1]-y)**2)/(n-1)
ve[2] <- var(y)
    # Varianza de la media de y
ybvar[1] <- ve[1]/n

# Con paquete survey:
library(survey)

  # Definir esquema de muestreo
muestra_svy <- svydesign(~1, data=muestra)
    # Media (incluye calculo de su varianza)
yb_svy <- svymean(y,muestra_svy)
    # Varianza de y
ve_svy <- svyvar(y,muestra_svy)

yb[3]<-yb_svy;ve[3]<-ve_svy
ybvar[2]<-attr(yb_svy, which = "var")

# Verificamos equivalencia de los metodos
yb;ve;ybvar
```
